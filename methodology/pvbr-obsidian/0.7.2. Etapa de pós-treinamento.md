Cada modelo encontrado no SOTA será treinado isoladamente para os dois *dataset* gerados, em sua totalidade e os reduzidos por PCA. Por meio das curvas de perda durante o treinamento e validação, será possível verificar o adequamento dos dados ao modelo e a progressiva melhora dele durante as épocas do treinamento, até que chegue a uma boa inércia. Durante a implementação de cada, é necessário atentar-se a dimensionalidade, tanto da inserção quanto da saída, dos dados.

Ambos estando devidamente treinados, as métricas de *Mean Squared Error* (MSE) e *Mean Absolute Error* (MAE) serão avaliadas em conjunto, a fim de detalhar somente a acuracidade obtida em avaliação de cada modelo. Tido o relatório avaliativo, a próxima etapa refere-se a visualização da importância de cada característica daquele modelo a ser analisado. Por meio do  *Shap Values* e da melhor época treinada para o modelo, por meio do conjunto de teste, o *framework* irá descrever o impacto que cada característica possui à inferência, demonstrando sua força para obter o devido valor.

$$MSE = \frac{1}{N}\sum_{i=1}^{N}(y_{i}-\dot{y}_{i})^2$$  $$MAE = \frac{1}{N}\sum_{i=1}^{N}|y_{i}-\dot{y}_{i}|$$ 
A etapa de interpretabilidade de característica também irá resultar em um conjunto de *features* que mais impactaram na previsão. É possível utilizá-las para retreinar o modelo e verificar novamente o comportamento durante o treinamento, avaliando-as e, consequentemente, obtendo o terceiro componente comparativo.

Dada a comparação feita do treinamento utilizando todas as *features* compiladas com as reduzidas por PCA e por sua interpretabilidade, e possível perceber a curva de perda e as métricas de erro vistas. Porém, como feito por \citeonline{[[brito-2021]]}, será realizada uma fusão tardia por votação para melhorar diminuir o erro entre a inferência e o real valor de consumo. A próxima subseção descreve o método adotado para obtenção desse objetivo.