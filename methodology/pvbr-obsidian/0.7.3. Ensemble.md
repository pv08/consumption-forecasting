Em busca de uma maior acuracidade, uma das formas mais utilizadas na liteuratura é a fusão dos modelos isoladamente treinados. Por meio da votação, é preciso atribuir diferentes pesos para cada um deles, de forma que, aquele que possui maior erro, contribuirá menos para a nova previsão. Para buscar esses pesos, é possível adotar uma combinação por *grid search*, onde dado um vetor de pesos, o algoritmo irá combinar de exaustivamente o melhor resultado. Utilizar essa maneira gera uma complexidade $O(n^y)$, onde $y$ é o número de modelos. Ou seja, para o pior caso, seria possível obter uma pesquisa exaustiva entre $y$ modelos, com $x$ valores possíveis de pesos.

Como descrito na Seção \ref{[[0.3.1. Simulated Annealing]]}, as meta-heurísticas de ombinação otimizatória podem a melhorar efetivamente a busca pelo ideal conjunto de pesos para melhor ponderar os modelos por sua acuracidade. 